{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import modeling as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_id = pd.read_csv('../new_ids_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_model=md.train_test(test_size = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_merged = md.read_datasets(list_data = ['final_txn_test_v2', 'final_user_log_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_merged.drop('is_churn', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_merged = test_merged.join(pd.get_dummies(test_merged['months_listening'])).drop('months_listening', axis = 1)\n",
    "test_merged = test_merged.join(pd.get_dummies(test_merged['cluster9'])).drop('cluster9', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_id</th>\n",
       "      <th>payment_plan_days</th>\n",
       "      <th>plan_list_price</th>\n",
       "      <th>actual_amount_paid</th>\n",
       "      <th>avg_daily_paid</th>\n",
       "      <th>list_actual_diff</th>\n",
       "      <th>mean_ar</th>\n",
       "      <th>stopped_ar</th>\n",
       "      <th>mean_cancel</th>\n",
       "      <th>last_cancel</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114238</td>\n",
       "      <td>630</td>\n",
       "      <td>2079</td>\n",
       "      <td>2079</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>645936</td>\n",
       "      <td>510</td>\n",
       "      <td>2533</td>\n",
       "      <td>3427</td>\n",
       "      <td>6.719608</td>\n",
       "      <td>64642</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>930346</td>\n",
       "      <td>300</td>\n",
       "      <td>1240</td>\n",
       "      <td>1001</td>\n",
       "      <td>3.336667</td>\n",
       "      <td>239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>581522</td>\n",
       "      <td>510</td>\n",
       "      <td>1683</td>\n",
       "      <td>1683</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>652144</td>\n",
       "      <td>120</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   new_id  payment_plan_days  plan_list_price  actual_amount_paid  \\\n",
       "0  114238                630             2079                2079   \n",
       "1  645936                510             2533                3427   \n",
       "2  930346                300             1240                1001   \n",
       "3  581522                510             1683                1683   \n",
       "4  652144                120              516                 516   \n",
       "\n",
       "   avg_daily_paid  list_actual_diff  mean_ar stopped_ar  mean_cancel  \\\n",
       "0        3.300000                 0      1.0      False     0.000000   \n",
       "1        6.719608             64642      1.0      False     0.000000   \n",
       "2        3.336667               239      1.0      False     0.181818   \n",
       "3        3.300000                 0      1.0      False     0.000000   \n",
       "4        4.300000                 0      1.0      False     0.000000   \n",
       "\n",
       "   last_cancel ...  0.0  1.0  2.0  3.0  4.0  5.0  6.0 7.0 8.0  9.0  \n",
       "0            0 ...    0    0    0    0    0    0    0   1   0    0  \n",
       "1            0 ...    0    1    0    0    0    0    0   0   0    0  \n",
       "2            0 ...    0    0    0    1    0    0    0   0   0    0  \n",
       "3            0 ...    0    0    0    0    0    0    0   0   0    1  \n",
       "4            0 ...    0    0    0    1    0    0    0   0   0    0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train = data_model['xtrain']\n",
    "X_test = data_model['xtest']\n",
    "y_train = data_model['ytrain']\n",
    "y_test = data_model['ytest']\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators= 100, criterion = 'entropy', random_state = 0, max_depth=15)\n",
    "forest.fit(X_train, y_train)\n",
    "y_pred = forest.predict(test_merged)\n",
    "y_prob = forest.predict_proba(test_merged)\n",
    "y_prob_train = forest.predict_proba(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Random Forest Train \\t{:.4f}' .format(log_loss(y_train, y_prob_train)))\n",
    "\n",
    "test_merged['is_churn'] = y_prob[:,1] \n",
    "\n",
    "test_f = test_merged[['new_id','is_churn']].merge(new_id, on='new_id', how='inner')\n",
    "\n",
    "test_f.drop('new_id', axis=1, inplace=True)\n",
    "test_f.to_csv('../test_prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(970960, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_id</th>\n",
       "      <th>payment_plan_days</th>\n",
       "      <th>plan_list_price</th>\n",
       "      <th>actual_amount_paid</th>\n",
       "      <th>avg_daily_paid</th>\n",
       "      <th>list_actual_diff</th>\n",
       "      <th>mean_ar</th>\n",
       "      <th>stopped_ar</th>\n",
       "      <th>mean_cancel</th>\n",
       "      <th>last_cancel</th>\n",
       "      <th>...</th>\n",
       "      <th>months_listening</th>\n",
       "      <th>listening_p6</th>\n",
       "      <th>listening_p12</th>\n",
       "      <th>logavg_secs_p12</th>\n",
       "      <th>freq_days</th>\n",
       "      <th>std_logsecs</th>\n",
       "      <th>total_entries</th>\n",
       "      <th>cluster9</th>\n",
       "      <th>freq_days_mean</th>\n",
       "      <th>ul_tenure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>988305</td>\n",
       "      <td>60.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>894.0</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>-596.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>True</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7-12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.738223</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.852721</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.086538</td>\n",
       "      <td>728.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>723425</td>\n",
       "      <td>127.0</td>\n",
       "      <td>627.0</td>\n",
       "      <td>627.0</td>\n",
       "      <td>4.937008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7-12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.306972</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.145499</td>\n",
       "      <td>80.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.110181</td>\n",
       "      <td>717.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1066360</td>\n",
       "      <td>540.0</td>\n",
       "      <td>2682.0</td>\n",
       "      <td>2682.0</td>\n",
       "      <td>4.966667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19-24</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.288232</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.415583</td>\n",
       "      <td>342.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.577966</td>\n",
       "      <td>590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>180122</td>\n",
       "      <td>787.0</td>\n",
       "      <td>3874.0</td>\n",
       "      <td>4172.0</td>\n",
       "      <td>5.301144</td>\n",
       "      <td>-298.0</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>True</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0-6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.618040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>372093</td>\n",
       "      <td>840.0</td>\n",
       "      <td>3222.0</td>\n",
       "      <td>3649.0</td>\n",
       "      <td>4.344048</td>\n",
       "      <td>-427.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25-27</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.571583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.205211</td>\n",
       "      <td>271.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.329268</td>\n",
       "      <td>820.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    new_id  payment_plan_days  plan_list_price  actual_amount_paid  \\\n",
       "0   988305               60.0            298.0               894.0   \n",
       "1   723425              127.0            627.0               627.0   \n",
       "2  1066360              540.0           2682.0              2682.0   \n",
       "3   180122              787.0           3874.0              4172.0   \n",
       "4   372093              840.0           3222.0              3649.0   \n",
       "\n",
       "   avg_daily_paid  list_actual_diff   mean_ar stopped_ar  mean_cancel  \\\n",
       "0       14.900000            -596.0  0.833333       True     0.166667   \n",
       "1        4.937008               0.0  0.000000      False     0.000000   \n",
       "2        4.966667               0.0  0.000000      False     0.000000   \n",
       "3        5.301144            -298.0  0.965517       True     0.103448   \n",
       "4        4.344048            -427.0  1.000000      False     0.096774   \n",
       "\n",
       "   last_cancel    ...     months_listening  listening_p6  listening_p12  \\\n",
       "0          0.0    ...                 7-12           1.0            1.0   \n",
       "1          0.0    ...                 7-12           1.0            6.0   \n",
       "2          0.0    ...                19-24           6.0           12.0   \n",
       "3          0.0    ...                  0-6           0.0            0.0   \n",
       "4          0.0    ...                25-27           6.0           12.0   \n",
       "\n",
       "   logavg_secs_p12  freq_days  std_logsecs  total_entries cluster9  \\\n",
       "0         8.738223        0.5     1.852721           64.0      3.0   \n",
       "1        10.306972        1.0     1.145499           80.0      7.0   \n",
       "2        11.288232        1.0     1.415583          342.0      5.0   \n",
       "3        -0.618040        0.0     0.000000            0.0      9.0   \n",
       "4        10.571583        1.0     1.205211          271.0      1.0   \n",
       "\n",
       "  freq_days_mean  ul_tenure  \n",
       "0       0.086538      728.0  \n",
       "1       0.110181      717.0  \n",
       "2       0.577966      590.0  \n",
       "3       0.000000        0.0  \n",
       "4       0.329268      820.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read datasets\n",
    "train_txn = pd.read_csv('../final_txn_v2.csv')\n",
    "train_user = pd.read_csv('../final_user_log_v2.csv')\n",
    "#merge datasets\n",
    "train = train_txn.merge(train_user, on='new_id', how='inner')\n",
    "#check datasets\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Repeated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#locate column of is_churn\n",
    "loc = train.columns.get_loc('is_churn')\n",
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87328, 33)\n",
      "(883632, 33)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(873280, 33)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change train dataset into numpy matrix and split into churned and did not churn\n",
    "train_np = train.values\n",
    "train_yes = train_np[train_np[:,loc] == 1, :]\n",
    "train_no = train_np[train_np[:,loc] == 0, :]\n",
    "print(train_yes.shape)\n",
    "print(train_no.shape)\n",
    "\n",
    "#Replicate churned sample\n",
    "ntrain_yes = train_yes.repeat(10, axis = 0)\n",
    "ntrain_yes.shape\n",
    "#new_train = np.concatenate(ntrain_yes, train_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-13cc21a14d04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m#Combine balanced sample into list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ml1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mntrain_yes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtrain_no\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mt_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mntrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mntrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Combine balanced sample into list\n",
    "l1 = ntrain_yes.tolist() + train_no.tolist()\n",
    "t_cols = train.columns\n",
    "ntrain = pd.DataFrame(l1, columns = t_cols)\n",
    "ntrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check for nulls\n",
    "cols = ntrain.columns\n",
    "\n",
    "for col in cols:\n",
    "    print ('%s:\\t\\t\\t %s Nulls' %(col ,len(ntrain[pd.isnull(ntrain[col]) == True]))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#change months listening into dummy variable\n",
    "ntrain = ntrain.join(pd.get_dummies(ntrain['months_listening'])).drop('months_listening', axis =1)\n",
    "ntrain.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Change clusters into dummy variable\n",
    "ntrain = ntrain.join(pd.get_dummies(ntrain['cluster9'], prefix = 'cluster')).drop('cluster9', axis =1)\n",
    "ntrain.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(ntrain[(pd.isnull(ntrain['listening_p6']) == True)]['new_id'].nunique())\n",
    "#ntrain[(pd.isnull(ntrain['payment_plan_days']) == True) & (ntrain['is_churn_x'] == 0)]['new_id'].nunique()\n",
    "#ntrain[(pd.isnull(ntrain['payment_plan_days']) == True) & (pd.isnull(ntrain['months_listening'] == True))]['new_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working With non-balanced Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['new_id', 'payment_plan_days', 'plan_list_price', 'actual_amount_paid',\n",
       "       'avg_daily_paid', 'list_actual_diff', 'mean_ar', 'stopped_ar',\n",
       "       'mean_cancel', 'last_cancel', 'lst_free_trial', 'per_free_trial',\n",
       "       'per_days_free_trial', 'txn_cnt', 'per_lp_high', 'prev_churn_per',\n",
       "       'pmt_change_cnt', 'not_equal', 'lst_memb_expire_post',\n",
       "       'memb_tenure_days', 'lst_memb_expire_days', 'is_churn', 'no_songs_cp6',\n",
       "       'listening_p6', 'listening_p12', 'logavg_secs_p12', 'freq_days',\n",
       "       'std_logsecs', 'total_entries', 'freq_days_mean', 'ul_tenure', '0-6',\n",
       "       '13-18', '19-24', '25-27', '7-12', 'cluster_0.0', 'cluster_1.0',\n",
       "       'cluster_2.0', 'cluster_3.0', 'cluster_4.0', 'cluster_5.0',\n",
       "       'cluster_6.0', 'cluster_7.0', 'cluster_8.0', 'cluster_9.0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.join(pd.get_dummies(train['months_listening'])).drop('months_listening', axis =1)\n",
    "train.columns\n",
    "train = train.join(pd.get_dummies(train['cluster9'], prefix = 'cluster')).drop('cluster9', axis =1)\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train['is_churn']\n",
    "X = train.drop('is_churn', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cathy\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Importing stuff from sklearn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "depths_ls = []\n",
    "logloss_ls = []\n",
    "\n",
    "for depth in range(7,15):\n",
    "    depths_ls.append(depth)\n",
    "    \n",
    "    #split test and train\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 1)\n",
    "\n",
    "    #reshape test and train\n",
    "    y_train = y_train.reshape(len(y_train), 1)\n",
    "    y_test = y_test.reshape(len(y_test), 1)\n",
    "\n",
    "    # Fitting Decision Tree Classification to the Training set\n",
    "    classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0, max_depth = depth)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results and probabilities\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    y_prob = classifier.predict_proba(X_test)\n",
    "\n",
    "    # Making the Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    #logloss\n",
    "    print(log_loss(y_test, y_prob))\n",
    "    logloss_ls.append(log_loss(y_test, y_prob))\n",
    "    #print ('Error: {:0.2f}%' .format(((cm[0][1]+ cm[1][0])/(cm[1][1]+ cm[0][0]))*100))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(depths_ls, logloss_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "accuracies.mean()\n",
    "accuracies.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "http://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import random forest classifier and grid search from sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "    \n",
    "classifier = RandomForestClassifier(n_estimators = 100, random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_prob = classifier.predict_proba(X_test)\n",
    "\n",
    "print(log_loss(y_test, y_prob))\n",
    "\n",
    "# Random Forest Grid Search\n",
    "parameters = [{\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}]\n",
    "\n",
    "#Grid search, optimizing for log loss\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'neg_log_loss',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "#Grid search results\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG Boost\n",
    "http://xgboost.readthedocs.io/en/latest/parameter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, log_loss\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_model=md.train_test(test_size = 0.2)\n",
    "X_train = data_model['xtrain']\n",
    "X_test = data_model['xtest']\n",
    "y_train = data_model['ytrain']\n",
    "y_test = data_model['ytest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4fb1fc01e9a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;31m# Predicting the Test set results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Cathy\\Anaconda3\\lib\\site-packages\\xgboost-0.6-py3.6.egg\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model)\u001b[0m\n\u001b[1;32m    505\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m                               verbose_eval=verbose, xgb_model=None)\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Cathy\\Anaconda3\\lib\\site-packages\\xgboost-0.6-py3.6.egg\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Cathy\\Anaconda3\\lib\\site-packages\\xgboost-0.6-py3.6.egg\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Cathy\\Anaconda3\\lib\\site-packages\\xgboost-0.6-py3.6.egg\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 896\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    897\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "classifier = XGBClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_prob = classifier.predict_proba(X_test)\n",
    "\n",
    "print(log_loss(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = XGBClassifier(n_estimators= 100, seed=0, colsample_bytree= 0.8, \n",
    "             objective= 'binary:logistic', max_depth= 7, min_child_weight= 5, learning_rate= 0.1, subsample= 0.8, eval_metric='logloss')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(test_merged)\n",
    "y_prob = clf.predict_proba(test_merged)\n",
    "y_prob_train = clf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Train \t0.1263\n"
     ]
    }
   ],
   "source": [
    "print('XG Boost Train \\t{:.4f}' .format(log_loss(y_train, y_prob_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_merged['is_churn'] = y_prob[:,1] \n",
    "\n",
    "test_f = test_merged[['new_id','is_churn']].merge(new_id, on='new_id', how='inner')\n",
    "\n",
    "test_f.drop('new_id', axis=1, inplace=True)\n",
    "test_f.to_csv('../test_prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_params = {}\n",
    "ind_params = {'n_estimators': 50, 'seed':0, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic', 'max_depth': 7, 'min_child_weight': 5, 'learning_rate': 0.1, 'subsample': 0.8}\n",
    "optimized_GBM = GridSearchCV(XGBClassifier(**ind_params), \n",
    "                            cv_params, \n",
    "                             scoring = 'neg_log_loss', cv = 5, n_jobs = -1) \n",
    "# Optimize for accuracy since that is the metric used in the Adult Data Set notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=7, min_child_weight=5, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0, silent=True,\n",
       "       subsample=1),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'learning_rate': [0.1, 0.01], 'subsample': [0.7, 0.9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='neg_log_loss', verbose=0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_GBM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cathy\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: -0.13623, std: 0.00064, params: {'learning_rate': 0.1, 'subsample': 0.7},\n",
       " mean: -0.13605, std: 0.00079, params: {'learning_rate': 0.1, 'subsample': 0.9},\n",
       " mean: -0.42232, std: 0.00017, params: {'learning_rate': 0.01, 'subsample': 0.7},\n",
       " mean: -0.42227, std: 0.00015, params: {'learning_rate': 0.01, 'subsample': 0.9}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_GBM.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
